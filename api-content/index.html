{"posts":[{"title":"Kafka 为什么速度那么快？【转】","content":"Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，因为寻址会比较消耗时间，但是实际上，Kafka的特性之一就是高吞吐率。即使是普通的服务器，Kafka也可以轻松支持每秒百万级的写入请求，超过了大部分的消息中间件，这种特性也使得Kafka在日志处理等海量数据场景广泛应用。下面从数据写入和读取两方面分析，为什么Kafka速度这么快。 写入数据 Kafka会把收到的消息都写入到硬盘中，它绝对不会丢失数据。为了优化写入速度Kafka采用了两个技术， 顺序写入 和 MMFile 。 顺序写入 磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。在顺序读写的情况下，某些优化场景磁盘的读写速度可以和内存持平。 因为硬盘是机械结构，每次读写都会寻址-&gt;写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最讨厌随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。而且Linux对于磁盘的读写优化也比较多，包括read-ahead和write-behind，磁盘缓存等。如果在内存做这些操作的时候，一个是JAVA对象的内存开销很大，另一个是随着堆内存数据的增多，JAVA的GC时间会变得很长，使用磁盘操作有以下几个好处： 磁盘顺序读写速度超过内存随机读写 JVM的GC效率低，内存占用大。使用磁盘可以避免这一问题 系统冷启动后，磁盘缓存依然可用 上图就展示了Kafka是如何写入数据的， 每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾（虚框部分）。 这种方法有一个缺陷—— 没有办法删除数据 ，所以Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示 读取到了第几条数据 。 两个消费者，Consumer1有两个offset分别对应Partition0、Partition1（假设每一个Topic一个Partition）；Consumer2有一个offset对应Partition2。这个offset是由客户端SDK负责保存的，Kafka的Broker完全无视这个东西的存在；一般情况下SDK会把它保存到zookeeper里面。(所以需要给Consumer提供zookeeper的地址)。 如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据。一是基于时间，二是基于partition文件大小。具体配置可以参看它的配置文档。 Memory Mapped Files 即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并 不是实时的写入硬盘 ，它充分利用了现代操作系统 分页存储 来利用内存提高I/O效率。 Memory Mapped Files(后面简称mmap)也被翻译成 内存映射文件 ，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。 通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。 使用这种方式可以获取很大的I/O提升， 省去了用户空间到内核空间 复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）也有一个很明显的缺陷——不可靠， 写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。 Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫 同步 (sync)；写入mmap之后立即返回Producer不调用flush叫 异步 (async)。 读取数据 Kafka在读取磁盘时做了哪些优化？ 基于sendfile实现Zero Copy 传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下： 调用read函数，文件数据被copy到内核缓冲区 read函数返回，文件数据从内核缓冲区copy到用户缓冲区 write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。 数据从socket缓冲区copy到相关协议引擎。 以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次copy操作： 硬盘—&gt;内核buf—&gt;用户buf—&gt;socket相关缓冲区—&gt;协议引擎 而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。 在内核版本2.1中，引入了sendfile系统调用，以简化网络上和两个本地文件之间的数据传输。 sendfile的引入不仅减少了数据复制，还减少了上下文切换。 sendfile(socket, file, len); 运行流程如下： sendfile系统调用，文件数据被copy至内核缓冲区 再从内核缓冲区copy至内核中socket相关的缓冲区 最后再socket相关的缓冲区copy到协议引擎 相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，sendfile实现了更简单的方式，再次减少了一次copy操作。 在apache，nginx，lighttpd等web服务器当中，都有一项sendfile相关的配置，使用sendfile可以大幅提升文件传输性能。 Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把文件发送给消费者，配合mmap作为文件读写方式，直接把它传给sendfile。 批量压缩 在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络IO，对于需要在广域网上的数据中心之间发送消息的数据流水线尤其如此。进行数据压缩会消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑。 如果每个消息都压缩，但是压缩率相对很低，所以Kafka使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩 Kafka允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩 Kafka支持多种压缩协议，包括Gzip和Snappy压缩协议 总结 Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合sendfile直接暴力输出。 引用 https://juejin.im/post/5ee0356ef265da76d66c33e0?utm_source=gold_browser_extension ","link":"https://kychill1986.github.io/post/kafka-wei-shi-me-su-du-na-me-kuai-zhuan/"},{"title":"RabbitMQ实现延迟消息【转】","content":"摘要 本文主要讲解mall整合RabbitMQ实现延迟消息的过程，以发送延迟消息取消超时订单为例。RabbitMQ是一个被广泛使用的开源消息队列。它是轻量级且易于部署的，它能支持多种消息协议。RabbitMQ可以部署在分布式和联合配置中，以满足高规模、高可用性的需求。 项目使用框架介绍 RabbitMQ RabbitMQ是一个被广泛使用的开源消息队列。它是轻量级且易于部署的，它能支持多种消息协议。RabbitMQ可以部署在分布式和联合配置中，以满足高规模、高可用性的需求。 业务场景说明 用于解决用户下单以后，订单超时如何取消订单的问题。 用户进行下单操作（会有锁定商品库存、使用优惠券、积分一系列的操作）； 生成订单，获取订单的id； 获取到设置的订单超时时间（假设设置的为60分钟不支付取消订单）； 按订单超时时间发送一个延迟消息给RabbitMQ，让它在订单超时后触发取消订单的操作； 如果用户没有支付，进行取消订单操作（释放锁定商品库存、返还优惠券、返回积分一系列操作）。 整合RabbitMQ实现延迟消息 在pom.xml中添加相关依赖 &lt;!--消息队列相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 修改SpringBoot配置文件 rabbitmq: host: localhost # rabbitmq的连接地址 port: 5672 # rabbitmq的连接端口号 virtual-host: /mall # rabbitmq的虚拟host username: mall # rabbitmq的用户名 password: mall # rabbitmq的密码 publisher-confirms: true #如果对异步消息需要回调必须设置为true 添加消息队列的枚举配置类QueueEnum 用于延迟消息队列及处理取消订单消息队列的常量定义，包括交换机名称、队列名称、路由键名称。 import lombok.Getter; /** * 消息队列枚举配置 * Created by macro on 2018/9/14. */ @Getter public enum QueueEnum { /** * 消息通知队列 */ QUEUE_ORDER_CANCEL(&quot;mall.order.direct&quot;, &quot;mall.order.cancel&quot;, &quot;mall.order.cancel&quot;), /** * 消息通知ttl队列 */ QUEUE_TTL_ORDER_CANCEL(&quot;mall.order.direct.ttl&quot;, &quot;mall.order.cancel.ttl&quot;, &quot;mall.order.cancel.ttl&quot;); /** * 交换名称 */ private String exchange; /** * 队列名称 */ private String name; /** * 路由键 */ private String routeKey; QueueEnum(String exchange, String name, String routeKey) { this.exchange = exchange; this.name = name; this.routeKey = routeKey; } } 添加RabbitMQ的配置 用于配置交换机、队列及队列与交换机的绑定关系。 import com.macro.mall.tiny.dto.QueueEnum; import org.springframework.amqp.core.*; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * 消息队列配置 * Created by macro on 2018/9/14. */ @Configuration public class RabbitMqConfig { /** * 订单消息实际消费队列所绑定的交换机 */ @Bean DirectExchange orderDirect() { return (DirectExchange) ExchangeBuilder .directExchange(QueueEnum.QUEUE_ORDER_CANCEL.getExchange()) .durable(true) .build(); } /** * 订单延迟队列队列所绑定的交换机 */ @Bean DirectExchange orderTtlDirect() { return (DirectExchange) ExchangeBuilder .directExchange(QueueEnum.QUEUE_TTL_ORDER_CANCEL.getExchange()) .durable(true) .build(); } /** * 订单实际消费队列 */ @Bean public Queue orderQueue() { return new Queue(QueueEnum.QUEUE_ORDER_CANCEL.getName()); } /** * 订单延迟队列（死信队列） */ @Bean public Queue orderTtlQueue() { return QueueBuilder .durable(QueueEnum.QUEUE_TTL_ORDER_CANCEL.getName()) .withArgument(&quot;x-dead-letter-exchange&quot;, QueueEnum.QUEUE_ORDER_CANCEL.getExchange())//到期后转发的交换机 .withArgument(&quot;x-dead-letter-routing-key&quot;, QueueEnum.QUEUE_ORDER_CANCEL.getRouteKey())//到期后转发的路由键 .build(); } /** * 将订单队列绑定到交换机 */ @Bean Binding orderBinding(DirectExchange orderDirect,Queue orderQueue){ return BindingBuilder .bind(orderQueue) .to(orderDirect) .with(QueueEnum.QUEUE_ORDER_CANCEL.getRouteKey()); } /** * 将订单延迟队列绑定到交换机 */ @Bean Binding orderTtlBinding(DirectExchange orderTtlDirect,Queue orderTtlQueue){ return BindingBuilder .bind(orderTtlQueue) .to(orderTtlDirect) .with(QueueEnum.QUEUE_TTL_ORDER_CANCEL.getRouteKey()); } } 在RabbitMQ管理页面可以看到以下交换机和队列 交换机及队列说明 mall.order.direct（取消订单消息队列所绑定的交换机）:绑定的队列为mall.order.cancel，一旦有消息以mall.order.cancel为路由键发过来，会发送到此队列。 mall.order.direct.ttl（订单延迟消息队列所绑定的交换机）:绑定的队列为mall.order.cancel.ttl，一旦有消息以mall.order.cancel.ttl为路由键发送过来，会转发到此队列，并在此队列保存一定时间，等到超时后会自动将消息发送到mall.order.cancel（取消订单消息消费队列）。 添加延迟消息的发送者CancelOrderSender 用于向订单延迟消息队列（mall.order.cancel.ttl）里发送消息。 import com.macro.mall.tiny.dto.QueueEnum; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.amqp.AmqpException; import org.springframework.amqp.core.AmqpTemplate; import org.springframework.amqp.core.Message; import org.springframework.amqp.core.MessagePostProcessor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; /** * 取消订单消息的发出者 * Created by macro on 2018/9/14. */ @Component public class CancelOrderSender { private static Logger LOGGER =LoggerFactory.getLogger(CancelOrderSender.class); @Autowired private AmqpTemplate amqpTemplate; public void sendMessage(Long orderId,final long delayTimes){ //给延迟队列发送消息 amqpTemplate.convertAndSend(QueueEnum.QUEUE_TTL_ORDER_CANCEL.getExchange(), QueueEnum.QUEUE_TTL_ORDER_CANCEL.getRouteKey(), orderId, new MessagePostProcessor() { @Override public Message postProcessMessage(Message message) throws AmqpException { //给消息设置延迟毫秒值 message.getMessageProperties().setExpiration(String.valueOf(delayTimes)); return message; } }); LOGGER.info(&quot;send delay message orderId:{}&quot;,orderId); } } 添加取消订单消息的接收者CancelOrderReceiver 用于从取消订单的消息队列（mall.order.cancel）里接收消息。 import com.macro.mall.tiny.service.OmsPortalOrderService; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.amqp.rabbit.annotation.RabbitHandler; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; /** * 取消订单消息的处理者 * Created by macro on 2018/9/14. */ @Component @RabbitListener(queues = &quot;mall.order.cancel&quot;) public class CancelOrderReceiver { private static Logger LOGGER =LoggerFactory.getLogger(CancelOrderReceiver.class); @Autowired private OmsPortalOrderService portalOrderService; @RabbitHandler public void handle(Long orderId){ LOGGER.info(&quot;receive delay message orderId:{}&quot;,orderId); portalOrderService.cancelOrder(orderId); } } 添加OmsPortalOrderService接口 import com.macro.mall.tiny.common.api.CommonResult; import com.macro.mall.tiny.dto.OrderParam; import org.springframework.transaction.annotation.Transactional; /** * 前台订单管理Service * Created by macro on 2018/8/30. */ public interface OmsPortalOrderService { /** * 根据提交信息生成订单 */ @Transactional CommonResult generateOrder(OrderParam orderParam); /** * 取消单个超时订单 */ @Transactional void cancelOrder(Long orderId); } 添加OmsPortalOrderService的实现类OmsPortalOrderServiceImpl import com.macro.mall.tiny.common.api.CommonResult; import com.macro.mall.tiny.component.CancelOrderSender; import com.macro.mall.tiny.dto.OrderParam; import com.macro.mall.tiny.service.OmsPortalOrderService; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; /** * 前台订单管理Service * Created by macro on 2018/8/30. */ @Service public class OmsPortalOrderServiceImpl implements OmsPortalOrderService { private static Logger LOGGER = LoggerFactory.getLogger(OmsPortalOrderServiceImpl.class); @Autowired private CancelOrderSender cancelOrderSender; @Override public CommonResult generateOrder(OrderParam orderParam) { //todo 执行一系类下单操作，具体参考mall项目 LOGGER.info(&quot;process generateOrder&quot;); //下单完成后开启一个延迟消息，用于当用户没有付款时取消订单（orderId应该在下单后生成） sendDelayMessageCancelOrder(11L); return CommonResult.success(null, &quot;下单成功&quot;); } @Override public void cancelOrder(Long orderId) { //todo 执行一系类取消订单操作，具体参考mall项目 LOGGER.info(&quot;process cancelOrder orderId:{}&quot;,orderId); } private void sendDelayMessageCancelOrder(Long orderId) { //获取订单超时时间，假设为60分钟 long delayTimes = 30 * 1000; //发送延迟消息 cancelOrderSender.sendMessage(orderId, delayTimes); } } 添加OmsPortalOrderController定义接口 import com.macro.mall.tiny.dto.OrderParam; import com.macro.mall.tiny.service.OmsPortalOrderService; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; /** * 订单管理Controller * Created by macro on 2018/8/30. */ @Controller @Api(tags = &quot;OmsPortalOrderController&quot;, description = &quot;订单管理&quot;) @RequestMapping(&quot;/order&quot;) public class OmsPortalOrderController { @Autowired private OmsPortalOrderService portalOrderService; @ApiOperation(&quot;根据购物车信息生成订单&quot;) @RequestMapping(value = &quot;/generateOrder&quot;, method = RequestMethod.POST) @ResponseBody public Object generateOrder(@RequestBody OrderParam orderParam) { return portalOrderService.generateOrder(orderParam); } } 进行接口测试 调用下单接口 注意：已经将延迟消息时间设置为30秒 项目源码地址 https://github.com/macrozheng/mall-learning/tree/master/mall-tiny-08 引用 https://juejin.im/post/5cff98986fb9a07ed36ea139 ","link":"https://kychill1986.github.io/post/rabbitmq-shi-xian-yan-chi-xiao-xi-zhuan/"},{"title":"RabbitMQ基本使用【转】","content":" 配置 访问RabbitMQ管理页面地址，查看是否安装成功（Linux下使用服务器IP访问即可）：http://localhost:15672/ 输入账号密码并登录，这里使用默认账号密码登录：guest guest 创建帐号并设置其角色为管理员：mall mall 创建一个新的虚拟host为：/mall 点击mall用户进入用户配置页面； 给mall用户配置该虚拟host的权限； 至此，RabbitMQ的配置完成。 5种消息模式 这5种消息模式是构建基于RabbitMQ的消息应用的基础，一定要牢牢掌握它们。学过RabbitMQ的朋友应该了解过这些消息模式的Java实现，这里我们使用Spring AMQP的形式来实现它们。 简单模式 简单模式是最简单的消息模式，它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。 模式示意图 Spring AMQP实现 首先需要在pom.xml中添加Spring AMQP的相关依赖； &lt;!--Spring AMQP依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 然后修改application.yml，添加RabbitMQ的相关配置； spring: rabbitmq: host: localhost port: 5672 virtual-host: /mall username: mall password: mall publisher-confirms: true #消息发送到交换器确认 publisher-returns: true #消息发送到队列确认 添加简单模式相关Java配置，创建一个名为simple.hello的队列、一个生产者和一个消费者； @Configuration public class SimpleRabbitConfig { @Bean public Queue hello() { return new Queue(&quot;simple.hello&quot;); } @Bean public SimpleSender simpleSender(){ return new SimpleSender(); } @Bean public SimpleReceiver simpleReceiver(){ return new SimpleReceiver(); } } 生产者通过send方法向队列simple.hello中发送消息； public class SimpleSender { private static final Logger LOGGER = LoggerFactory.getLogger(SimpleSender.class); @Autowired private RabbitTemplate template; private static final String queueName=&quot;simple.hello&quot;; public void send() { String message = &quot;Hello World!&quot;; this.template.convertAndSend(queueName, message); LOGGER.info(&quot; [x] Sent '{}'&quot;, message); } } 消费者从队列simple.hello中获取消息； @RabbitListener(queues = &quot;simple.hello&quot;) public class SimpleReceiver { private static final Logger LOGGER = LoggerFactory.getLogger(SimpleReceiver.class); @RabbitHandler public void receive(String in) { LOGGER.info(&quot; [x] Received '{}'&quot;, in); } } 在controller中添加测试接口，调用该接口开始发送消息； @Controller @RequestMapping(&quot;/rabbit&quot;) public class RabbitController { @Autowired private SimpleSender simpleSender; @ApiOperation(&quot;简单模式&quot;) @RequestMapping(value = &quot;/simple&quot;, method = RequestMethod.GET) @ResponseBody public CommonResult simpleTest() { for(int i=0;i&lt;10;i++){ simpleSender.send(); ThreadUtil.sleep(1000); } return CommonResult.success(null); } } 运行后结果如下，可以发现生产者往队列中发送消息，消费者从队列中获取消息并消费。 工作模式 工作模式是指向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。 模式示意图 Spring AMQP实现 添加工作模式相关Java配置，创建一个名为work.hello的队列、一个生产者和两个消费者； @Configuration public class WorkRabbitConfig { @Bean public Queue workQueue() { return new Queue(&quot;work.hello&quot;); } @Bean public WorkReceiver workReceiver1() { return new WorkReceiver(1); } @Bean public WorkReceiver workReceiver2() { return new WorkReceiver(2); } @Bean public WorkSender workSender() { return new WorkSender(); } } 生产者通过send方法向队列work.hello中发送消息，消息中包含一定数量的.号； public class WorkSender { private static final Logger LOGGER = LoggerFactory.getLogger(WorkSender.class); @Autowired private RabbitTemplate template; private static final String queueName = &quot;work.hello&quot;; public void send(int index) { StringBuilder builder = new StringBuilder(&quot;Hello&quot;); int limitIndex = index % 3+1; for (int i = 0; i &lt; limitIndex; i++) { builder.append('.'); } builder.append(index+1); String message = builder.toString(); template.convertAndSend(queueName, message); LOGGER.info(&quot; [x] Sent '{}'&quot;, message); } } 两个消费者从队列work.hello中获取消息，名称分别为instance 1和instance 2，消息中包含.号越多，耗时越长； @RabbitListener(queues = &quot;work.hello&quot;) public class WorkReceiver { private static final Logger LOGGER = LoggerFactory.getLogger(WorkReceiver.class); private final int instance; public WorkReceiver(int i) { this.instance = i; } @RabbitHandler public void receive(String in) { StopWatch watch = new StopWatch(); watch.start(); LOGGER.info(&quot;instance {} [x] Received '{}'&quot;, this.instance, in); doWork(in); watch.stop(); LOGGER.info(&quot;instance {} [x] Done in {}s&quot;, this.instance, watch.getTotalTimeSeconds()); } private void doWork(String in) { for (char ch : in.toCharArray()) { if (ch == '.') { ThreadUtil.sleep(1000); } } } } 在controller中添加测试接口，调用该接口开始发送消息； @Controller @RequestMapping(&quot;/rabbit&quot;) public class RabbitController { @Autowired private WorkSender workSender; @ApiOperation(&quot;工作模式&quot;) @RequestMapping(value = &quot;/work&quot;, method = RequestMethod.GET) @ResponseBody public CommonResult workTest() { for(int i=0;i&lt;10;i++){ workSender.send(i); ThreadUtil.sleep(1000); } return CommonResult.success(null); } } 运行后结果如下，可以发现生产者往队列中发送包含不同数量.号的消息，instance 1和instance 2消费者互相竞争，分别消费了一部分消息。 发布/订阅模式 发布/订阅模式是指同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。 模式示意图 Spring AMQP实现 添加发布/订阅模式相关Java配置，创建一个名为exchange.fanout的交换机、一个生产者、两个消费者和两个匿名队列，将两个匿名队列都绑定到交换机； @Configuration public class FanoutRabbitConfig { @Bean public FanoutExchange fanout() { return new FanoutExchange(&quot;exchange.fanout&quot;); } @Bean public Queue fanoutQueue1() { return new AnonymousQueue(); } @Bean public Queue fanoutQueue2() { return new AnonymousQueue(); } @Bean public Binding fanoutBinding1(FanoutExchange fanout, Queue fanoutQueue1) { return BindingBuilder.bind(fanoutQueue1).to(fanout); } @Bean public Binding fanoutBinding2(FanoutExchange fanout, Queue fanoutQueue2) { return BindingBuilder.bind(fanoutQueue2).to(fanout); } @Bean public FanoutReceiver fanoutReceiver() { return new FanoutReceiver(); } @Bean public FanoutSender fanoutSender() { return new FanoutSender(); } } 生产者通过send方法向交换机exchange.fanout中发送消息，消息中包含一定数量的.号； public class FanoutReceiver { private static final Logger LOGGER = LoggerFactory.getLogger(FanoutReceiver.class); @RabbitListener(queues = &quot;#{fanoutQueue1.name}&quot;) public void receive1(String in) { receive(in, 1); } @RabbitListener(queues = &quot;#{fanoutQueue2.name}&quot;) public void receive2(String in) { receive(in, 2); } private void receive(String in, int receiver) { StopWatch watch = new StopWatch(); watch.start(); LOGGER.info(&quot;instance {} [x] Received '{}'&quot;, receiver, in); doWork(in); watch.stop(); LOGGER.info(&quot;instance {} [x] Done in {}s&quot;, receiver, watch.getTotalTimeSeconds()); } private void doWork(String in) { for (char ch : in.toCharArray()) { if (ch == '.') { ThreadUtil.sleep(1000); } } } } 消费者从绑定的匿名队列中获取消息，消息中包含.号越多，耗时越长，由于该消费者可以从两个队列中获取并消费消息，可以看做两个消费者，名称分别为instance 1和instance 2； public class FanoutSender { private static final Logger LOGGER = LoggerFactory.getLogger(FanoutSender.class); @Autowired private RabbitTemplate template; private static final String exchangeName = &quot;exchange.fanout&quot;; public void send(int index) { StringBuilder builder = new StringBuilder(&quot;Hello&quot;); int limitIndex = index % 3 + 1; for (int i = 0; i &lt; limitIndex; i++) { builder.append('.'); } builder.append(index + 1); String message = builder.toString(); template.convertAndSend(exchangeName, &quot;&quot;, message); LOGGER.info(&quot; [x] Sent '{}'&quot;, message); } } 在controller中添加测试接口，调用该接口开始发送消息； @Controller @RequestMapping(&quot;/rabbit&quot;) public class RabbitController { @Autowired private FanoutSender fanoutSender; @ApiOperation(&quot;发布/订阅模式&quot;) @RequestMapping(value = &quot;/fanout&quot;, method = RequestMethod.GET) @ResponseBody public CommonResult fanoutTest() { for(int i=0;i&lt;10;i++){ fanoutSender.send(i); ThreadUtil.sleep(1000); } return CommonResult.success(null); } } 运行后结果如下，可以发现生产者往队列中发送包含不同数量.号的消息，instance 1和instance 2同时获取并消费了消息。 路由模式 路由模式是可以根据路由键选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键转发到不同队列，队列绑定的消费者接收并消费消息。 模式示意图 Spring AMQP实现 添加路由模式相关Java配置，创建一个名为exchange.direct的交换机、一个生产者、两个消费者和两个匿名队列，队列通过路由键都绑定到交换机，队列1的路由键为orange和black，队列2的路由键为green和black； @Configuration public class DirectRabbitConfig { @Bean public DirectExchange direct() { return new DirectExchange(&quot;exchange.direct&quot;); } @Bean public Queue directQueue1() { return new AnonymousQueue(); } @Bean public Queue directQueue2() { return new AnonymousQueue(); } @Bean public Binding directBinding1a(DirectExchange direct, Queue directQueue1) { return BindingBuilder.bind(directQueue1).to(direct).with(&quot;orange&quot;); } @Bean public Binding directBinding1b(DirectExchange direct, Queue directQueue1) { return BindingBuilder.bind(directQueue1).to(direct).with(&quot;black&quot;); } @Bean public Binding directBinding2a(DirectExchange direct, Queue directQueue2) { return BindingBuilder.bind(directQueue2).to(direct).with(&quot;green&quot;); } @Bean public Binding directBinding2b(DirectExchange direct, Queue directQueue2) { return BindingBuilder.bind(directQueue2).to(direct).with(&quot;black&quot;); } @Bean public DirectReceiver receiver() { return new DirectReceiver(); } @Bean public DirectSender directSender() { return new DirectSender(); } } 生产者通过send方法向交换机exchange.direct中发送消息，发送时使用不同的路由键，根据路由键会被转发到不同的队列； public class DirectSender { @Autowired private RabbitTemplate template; private static final String exchangeName = &quot;exchange.direct&quot;; private final String[] keys = {&quot;orange&quot;, &quot;black&quot;, &quot;green&quot;}; private static final Logger LOGGER = LoggerFactory.getLogger(DirectSender.class); public void send(int index) { StringBuilder builder = new StringBuilder(&quot;Hello to &quot;); int limitIndex = index % 3; String key = keys[limitIndex]; builder.append(key).append(' '); builder.append(index+1); String message = builder.toString(); template.convertAndSend(exchangeName, key, message); LOGGER.info(&quot; [x] Sent '{}'&quot;, message); } } 消费者从自己绑定的匿名队列中获取消息，由于该消费者可以从两个队列中获取并消费消息，可以看做两个消费者，名称分别为instance 1和instance 2； public class DirectReceiver { private static final Logger LOGGER = LoggerFactory.getLogger(DirectReceiver.class); @RabbitListener(queues = &quot;#{directQueue1.name}&quot;) public void receive1(String in){ receive(in, 1); } @RabbitListener(queues = &quot;#{directQueue2.name}&quot;) public void receive2(String in){ receive(in, 2); } private void receive(String in, int receiver){ StopWatch watch = new StopWatch(); watch.start(); LOGGER.info(&quot;instance {} [x] Received '{}'&quot;, receiver, in); doWork(in); watch.stop(); LOGGER.info(&quot;instance {} [x] Done in {}s&quot;, receiver, watch.getTotalTimeSeconds()); } private void doWork(String in){ for (char ch : in.toCharArray()) { if (ch == '.') { ThreadUtil.sleep(1000); } } } } 在controller中添加测试接口，调用该接口开始发送消息； @Controller @RequestMapping(&quot;/rabbit&quot;) public class RabbitController { @Autowired private DirectSender directSender; @ApiOperation(&quot;路由模式&quot;) @RequestMapping(value = &quot;/direct&quot;, method = RequestMethod.GET) @ResponseBody public CommonResult directTest() { for(int i=0;i&lt;10;i++){ directSender.send(i); ThreadUtil.sleep(1000); } return CommonResult.success(null); } } 运行后结果如下，可以发现生产者往队列中发送包含不同路由键的消息，instance 1获取到了orange和black消息，instance 2获取到了green和black消息。 通配符模式 通配符模式是可以根据路由键匹配规则选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键匹配规则绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键匹配规则转发到不同队列，队列绑定的消费者接收并消费消息。 特殊匹配符号 *：只能匹配一个单词； #：可以匹配零个或多个单词。 模式示意图 Spring AMQP实现 添加通配符模式相关Java配置，创建一个名为exchange.topic的交换机、一个生产者、两个消费者和两个匿名队列，匹配*.orange.和.*.rabbit发送到队列1，匹配lazy.#发送到队列2； @Configuration public class TopicRabbitConfig { @Bean public TopicExchange topic() { return new TopicExchange(&quot;exchange.topic&quot;); } @Bean public Queue topicQueue1() { return new AnonymousQueue(); } @Bean public Queue topicQueue2() { return new AnonymousQueue(); } @Bean public Binding topicBinding1a(TopicExchange topic, Queue topicQueue1) { return BindingBuilder.bind(topicQueue1).to(topic).with(&quot;*.orange.*&quot;); } @Bean public Binding topicBinding1b(TopicExchange topic, Queue topicQueue1) { return BindingBuilder.bind(topicQueue1).to(topic).with(&quot;*.*.rabbit&quot;); } @Bean public Binding topicBinding2a(TopicExchange topic, Queue topicQueue2) { return BindingBuilder.bind(topicQueue2).to(topic).with(&quot;lazy.#&quot;); } @Bean public TopicReceiver topicReceiver() { return new TopicReceiver(); } @Bean public TopicSender topicSender() { return new TopicSender(); } } 生产者通过send方法向交换机exchange.topic中发送消息，消息中包含不同的路由键； public class TopicSender { @Autowired private RabbitTemplate template; private static final String exchangeName = &quot;exchange.topic&quot;; private static final Logger LOGGER = LoggerFactory.getLogger(TopicSender.class); private final String[] keys = {&quot;quick.orange.rabbit&quot;, &quot;lazy.orange.elephant&quot;, &quot;quick.orange.fox&quot;, &quot;lazy.brown.fox&quot;, &quot;lazy.pink.rabbit&quot;, &quot;quick.brown.fox&quot;}; public void send(int index) { StringBuilder builder = new StringBuilder(&quot;Hello to &quot;); int limitIndex = index%keys.length; String key = keys[limitIndex]; builder.append(key).append(' '); builder.append(index+1); String message = builder.toString(); template.convertAndSend(exchangeName, key, message); LOGGER.info(&quot; [x] Sent '{}'&quot;,message); System.out.println(&quot; [x] Sent '&quot; + message + &quot;'&quot;); } } 消费者从自己绑定的匿名队列中获取消息，由于该消费者可以从两个队列中获取并消费消息，可以看做两个消费者，名称分别为instance 1和instance 2； public class TopicReceiver { private static final Logger LOGGER = LoggerFactory.getLogger(TopicReceiver.class); @RabbitListener(queues = &quot;#{topicQueue1.name}&quot;) public void receive1(String in){ receive(in, 1); } @RabbitListener(queues = &quot;#{topicQueue2.name}&quot;) public void receive2(String in){ receive(in, 2); } public void receive(String in, int receiver){ StopWatch watch = new StopWatch(); watch.start(); LOGGER.info(&quot;instance {} [x] Received '{}'&quot;, receiver, in); doWork(in); watch.stop(); LOGGER.info(&quot;instance {} [x] Done in {}s&quot;, receiver, watch.getTotalTimeSeconds()); } private void doWork(String in){ for (char ch : in.toCharArray()) { if (ch == '.') { ThreadUtil.sleep(1000); } } } } 在controller中添加测试接口，调用该接口开始发送消息； @Controller @RequestMapping(&quot;/rabbit&quot;) public class RabbitController { @Autowired private TopicSender topicSender; @ApiOperation(&quot;通配符模式&quot;) @RequestMapping(value = &quot;/topic&quot;, method = RequestMethod.GET) @ResponseBody public CommonResult topicTest() { for(int i=0;i&lt;10;i++){ topicSender.send(i); ThreadUtil.sleep(1000); } return CommonResult.success(null); } } 运行后结果如下，可以发现生产者往队列中发送包含不同路由键的消息，instance 1和instance 2分别获取到了匹配的消息。 源码 https://github.com/macrozheng/mall-learning/tree/master/mall-tiny-rabbit 引用 https://mp.weixin.qq.com/s/qGg3etLnI38i-G8aFbulWw ","link":"https://kychill1986.github.io/post/rabbitmq-ji-ben-shi-yong-zhuan/"},{"title":"ElasticSearch中composite聚合的使用【转】","content":"简介composite composite是一个多桶聚合，它从不同的源创建复合桶，与其他多桶聚合不同，复合聚合可用于高效地对多级聚合中的所有桶进行分页。这种聚合提供了一种方法来流特定聚合的所有桶，类似于滚动对文档所做的操作。 组合桶是由为每个文档提取/创建的值的组合构建的，每个组合被视为组合桶。如下为官方给的例子： { &quot;keyword&quot;: [&quot;foo&quot;, &quot;bar&quot;], &quot;number&quot;: [23, 65, 76] } 如果我们同时对keyword和number两个字段进行聚合会得出以下的结果: { &quot;keyword&quot;: &quot;foo&quot;, &quot;number&quot;: 23 } { &quot;keyword&quot;: &quot;foo&quot;, &quot;number&quot;: 65 } { &quot;keyword&quot;: &quot;foo&quot;, &quot;number&quot;: 76 } { &quot;keyword&quot;: &quot;bar&quot;, &quot;number&quot;: 23 } { &quot;keyword&quot;: &quot;bar&quot;, &quot;number&quot;: 65 } { &quot;keyword&quot;: &quot;bar&quot;, &quot;number&quot;: 76 } 看到上面的例子是不是恍然大悟， 就像类似sql中的多group by 多字段，可以对多个字段进行聚合，这非常适用于对于多维度出报表的需求，我这里建议使用的版本为6.5+，因为6.5版本以下此功能还处于测试阶段，设计和代码没有正式的GA功能成熟，并且没有担保。当然我这里也会提供6.5版本以下如何进行多聚合字段的使用。 首先上官方文档地址: https://www.elastic.co/guide/en/elasticsearch/reference/6.5/search-aggregations-bucket-composite-aggregation.html 其实官方文档已经把该功能说得很详细，如果你只是单纯写DSL实现的话看官方文档就可以，我接下来就介绍如何调用他的javaAPI来使用，当然如果阅读源码能力强的话也可以直接看官方在github的test,地址如下: https://github.com/elastic/elasticsearch/tree/master/server/src/test/java/org/elasticsearch/search/aggregations/bucket/composite 验证多字段聚合可行性 上面的例子为官方例子，我们需要自己弄个例子检查可行性，我们现在创建一个index,索引名为composite_test,mapping如下 { &quot;area&quot; : { &quot;type&quot; : &quot;keyword&quot; }, &quot;userid&quot; : { &quot;type&quot; : &quot;keyword&quot; }, &quot;sendtime&quot; : { &quot;type&quot; : &quot;date&quot;, &quot;format&quot; : &quot;yyyy-MM-dd HH:mm:ss&quot; } } 我们创建好了index，index中一共有三个字段，area，userid，sendtime三个字段，我们也使用MySQL数据建一个一模一样的表，方便对比聚合出来的数据是否正确，表名为composite_test。 我们首先对数据表composite_test插入5条记录，分别如下 使用group by对三个字段进行聚合，以下为在数据库中的实现： SELECT COUNT(1),area,userid,sendtime FROM composite_test GROUP BY area,userid,sendtime 结果如下: 以上为数据库的聚合实现，所以我们使用ES进行多字段聚合的时候如果结果和以上的一样则是正确的，我们也一样往ES composite_test索引中 插入相同的5条数据,在kibana上执行以下命令插入。 POST composite_test/_bulk { &quot;index&quot; : {&quot;_type&quot; :&quot;_doc&quot;}} {&quot;area&quot;:&quot;33&quot;,&quot;userid&quot;:&quot;400015&quot;,&quot;sendtime&quot;:&quot;2019-01-17 00:00:00&quot;} { &quot;index&quot; : {&quot;_type&quot; : &quot;_doc&quot;}} {&quot;area&quot;:&quot;33&quot;,&quot;userid&quot;:&quot;400015&quot;,&quot;sendtime&quot;:&quot;2019-01-17 00:00:00&quot;} { &quot;index&quot; : {&quot;_type&quot; : &quot;_doc&quot;}} {&quot;area&quot;:&quot;35&quot;,&quot;userid&quot;:&quot;400016&quot;,&quot;sendtime&quot;:&quot;2019-01-18 00:00:00&quot;} { &quot;index&quot; : { &quot;_type&quot; : &quot;_doc&quot;}} {&quot;area&quot;:&quot;35&quot;,&quot;userid&quot;:&quot;400016&quot;,&quot;sendtime&quot;:&quot;2019-01-18 00:00:00&quot;} { &quot;index&quot; : {&quot;_type&quot; : &quot;_doc&quot;}} {&quot;area&quot;:&quot;33&quot;,&quot;userid&quot;:&quot;400017&quot;,&quot;sendtime&quot;:&quot;2019-01-17 00:00:00&quot;} 查询ES，我们发现已经存在了这5条数据了。 接下来我们先使用composite的DSL查询： GET composite_test/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;my_buckets&quot;: { &quot;composite&quot; : { &quot;sources&quot; : [ { &quot;area&quot;: { &quot;terms&quot;: {&quot;field&quot;: &quot;area&quot; } } }, { &quot;userid&quot;: { &quot;terms&quot;: {&quot;field&quot;: &quot;userid&quot; } } }, { &quot;sendtime&quot;: { &quot;date_histogram&quot;: { &quot;field&quot;: &quot;sendtime&quot;,&quot;interval&quot;: &quot;1d&quot;,&quot;format&quot;: &quot;yyyy-MM-dd&quot;} } } ] } } } } DSL中参数的意思请自行参考官方文档，都说得很详细的,以上这句理论上是等值于数据库的那句聚合语句的，查询结果如下 [ { &quot;key&quot; : { &quot;area&quot; : &quot;33&quot;, &quot;userid&quot; : &quot;400015&quot;, &quot;sendtime&quot; : &quot;2019-01-17&quot; }, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : { &quot;area&quot; : &quot;33&quot;, &quot;userid&quot; : &quot;400017&quot;, &quot;sendtime&quot; : &quot;2019-01-17&quot; }, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : { &quot;area&quot; : &quot;35&quot;, &quot;userid&quot; : &quot;400016&quot;, &quot;sendtime&quot; : &quot;2019-01-18&quot; }, &quot;doc_count&quot; : 2 } ] 从以上响应的json数组中我们不难看出，该聚合聚合出来的数据是和数据库聚合出来的数据是一致的，所以 composite是可以使用在多字段聚合上的。论证完可行性，我们接下来使用java来实现，实话说这一块我是看源代码才会使用的，网上资料基本为0，而且官方java使用文档里也没用，的确是与遇到了不少坑，写出来方便以后使用能快速回忆。 java使用composite聚合 首先创建Maven项目,加入ElasticSearch依赖： &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.5.4&lt;/version&gt; &lt;/dependency&gt; 直接上实现代码: SearchRequest searchRequest = new SearchRequest(&quot;composite_test&quot;); searchRequest.types(&quot;_doc&quot;); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.size(0); /********************以下组装聚合的三个字段****************************/ List&lt;CompositeValuesSourceBuilder&lt;?&gt;&gt; sources = new ArrayList&lt;&gt;(); DateHistogramValuesSourceBuilder sendtime = new DateHistogramValuesSourceBuilder(&quot;sendtime&quot;) .field(&quot;sendtime&quot;) .dateHistogramInterval(DateHistogramInterval.days(1)) .format(&quot;yyyy-MM-dd&quot;).order(SortOrder.DESC).missingBucket(false); sources.add(sendtime); TermsValuesSourceBuilder userid = new TermsValuesSourceBuilder(&quot;userid&quot;).field(&quot;userid&quot;).missingBucket(true); sources.add(userid); TermsValuesSourceBuilder dttype = new TermsValuesSourceBuilder(&quot;area&quot;).field(&quot;area&quot;).missingBucket(true); sources.add(dttype); CompositeAggregationBuilder composite =new CompositeAggregationBuilder(&quot;my_buckets&quot;, sources); composite.size(1000); /*********************执行查询******************************/ searchSourceBuilder.aggregation(composite); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = client.search(searchRequest,RequestOptions.DEFAULT); /********************取出数据*******************/ Aggregations aggregations = searchResponse.getAggregations(); ParsedComposite parsedComposite = aggregations.get(&quot;my_buckets&quot;); List&lt;ParsedBucket&gt; list = parsedComposite.getBuckets(); Map&lt;String,Object&gt; data = new HashMap&lt;&gt;(); for(ParsedBucket parsedBucket:list){ data.clear(); for (Map.Entry&lt;String, Object&gt; m : parsedBucket.getKey().entrySet()) { data.put(m.getKey(),m.getValue()); } data.put(&quot;count&quot;,parsedBucket.getDocCount()); System.out.println(data); } /*************************************/ 代码中的client为RestHighLevelClient，请自行初始化，然后执行代码，控制台打印如下: {area=35, count=2, sendtime=2019-01-18, userid=400016} {area=33, count=2, sendtime=2019-01-17, userid=400015} {area=33, count=1, sendtime=2019-01-17, userid=400017} 数据正确，方法可用，其实这个方法是RestHighLevelClient替我们封装了composite生成DSL。 这里注意一下missingBucket的设置，这个的意思是如果该字段没值，为true的时候会返回null，为false不返回整条数据，注意这里是整条数据，而不是单单这个字段而已。 低版本使用ES多字段聚合 以上就是composite的验证和在java中的使用方法，建议在6.5+版本使用，但这个时候小伙伴可能会问，如果我是6.5以下的版本呢，这里我也有一个方法，只不过是有点绕，直接上代码： SearchRequest searchRequest = new SearchRequest(&quot;composite_test&quot;); searchRequest.types(&quot;_doc&quot;); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.size(0); /********************以下组装聚合的三个字段****************************/ AggregationBuilder sendtime=AggregationBuilders.dateHistogram(&quot;sendtime&quot;).field(&quot;sendtime&quot;).format(&quot;yyyy-MM-dd&quot;).interval(86400000); AggregationBuilder area=AggregationBuilders.terms(&quot;area&quot;).field(&quot;area&quot;); AggregationBuilder userid=AggregationBuilders.terms(&quot;userid&quot;).field(&quot;userid&quot;); //实现功能关键点 area.subAggregation(userid); sendtime.subAggregation(area); /*********************执行查询******************************/ searchSourceBuilder.aggregation(sendtime); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = client.search(searchRequest,RequestOptions.DEFAULT); /********************取出数据*******************/ Aggregations aggregations = searchResponse.getAggregations(); //取出数据 aggHandle(aggregations); /*************************************/ 运行响应的数据为 {area=33, count=2, sendtime=2019-01-17, userid=400015}, {area=33, count=1, sendtime=2019-01-17, userid=400017}, {area=35, count=2, sendtime=2019-01-18, userid=400016} 所以使用这个方法也能多值聚合数据，其中实现的关键点在于 area.subAggregation(userid); sendtime.subAggregation(area); 这里相当于把每个桶给串联起来，串联顺序无要求，但用这种方法最后取数据的时候比较麻烦，我这里也分享一个我取数据的方法 private static List&lt;Map&lt;String,Object&gt;&gt; listmap =new ArrayList&lt;Map&lt;String,Object&gt;&gt;(); private static Map&lt;String,Object&gt; map =new HashMap&lt;String,Object&gt;(16); //使用递归的方式将聚合数据中的数据一一取出来 private static void aggHandle(Aggregations agg){ String name =&quot;&quot;; Long longValue = 0L; for(Aggregation data:agg){ name = data.getName(); Object obj = agg.get(name); if(obj instanceof Terms){ Terms terms = (Terms) obj; name = terms.getName(); if(terms.getBuckets().size()==0){ listmap.add(clonMap(map)); } for (Terms.Bucket entry : terms.getBuckets()) { map.put(name, entry.getKey()); longValue = entry.getDocCount(); map.put(count, longValue); List&lt;Aggregation&gt; list = entry.getAggregations().asList(); if(list==null||list.isEmpty()){ listmap.add(clonMap(map)); }else{ aggHandle(entry.getAggregations()); } } }else if(obj instanceof ParsedDateHistogram){ ParsedDateHistogram terms = (ParsedDateHistogram) obj; List&lt;? extends Bucket&gt; buckets = terms.getBuckets(); name = terms.getName(); if(buckets.size()==0){ listmap.add(clonMap(map)); } for(Bucket entry:buckets){ map.put(name,entry.getKeyAsString()); longValue = entry.getDocCount(); map.put(count, longValue); List&lt;Aggregation&gt; list = entry.getAggregations().asList(); if(list==null||list.isEmpty()){ listmap.add(clonMap(map)); //map.clear(); }else{ aggHandle(entry.getAggregations()); } } }else if(obj instanceof Max){ Max max =(Max) obj; name = max.getName(); Double value = max.getValue(); longValue =value.longValue(); map.put(name, longValue); listmap.add(clonMap(map)); }else if(obj instanceof Min){ Min min =(Min) obj; Double value = min.getValue(); longValue =value.longValue(); map.put(min.getName(), longValue); listmap.add(clonMap(map)); }else if(obj instanceof Avg){ Avg avg = (Avg) obj; Double value = avg.getValue(); longValue =value.longValue(); map.put(avg.getName(), longValue); listmap.add(clonMap(map)); }else if(obj instanceof Sum){ Sum sum = (Sum) obj; Double value = sum.getValue(); longValue =value.longValue(); map.put(sum.getName(), longValue); listmap.add(clonMap(map)); }else if(obj instanceof ValueCount){ ValueCount count = (ValueCount) obj; longValue =count.getValue(); map.put(count.getName(), longValue); listmap.add(clonMap(map)); }else{ System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;+obj); } } } /** * 克隆map对象到另外一个map对象里面去 * @param map * @return */ private static Map&lt;String,Object&gt; clonMap(Map&lt;String,Object&gt; mapTo){ Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;(16); for (Map.Entry&lt;String,Object&gt; entry : mapTo.entrySet()) { String key = entry.getKey(); Object value = entry.getValue(); map.put(key, value); } return map; } Group by, Sum操作 SELECT sum(num), COUNT(1), area,userid,sendtime FROM composite_test GROUP BY area,userid,sendtime GET composite_test/_search { &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;my_buckets&quot;: { &quot;composite&quot;: { &quot;sources&quot;: [ { &quot;area&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;area&quot; } } }, { &quot;userid&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;userid&quot; } } }, { &quot;sendtime&quot;: { &quot;date_histogram&quot;: { &quot;field&quot;: &quot;sendtime&quot;, &quot;interval&quot;: &quot;1d&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot; } } } ], &quot;size&quot;: 10000 }, &quot;aggs&quot;: { &quot;sum_num&quot;: { &quot;sum&quot;: { &quot;field&quot;: &quot;num&quot; } } } } } } https://blog.csdn.net/qq_18895659/article/details/86540548 https://www.elastic.co/guide/en/elasticsearch/reference/6.5/search-aggregations-bucket-composite-aggregation.html ","link":"https://kychill1986.github.io/post/elasticsearch-zhong-composite-ju-he-de-shi-yong-zhuan/"},{"title":"Java 8 BiFunction 和 BiConsumer使用","content":"BiFunction 这里提醒一点，可以看出该接口中有方法的实现，不单单只有抽象方法，在java8中，有一个新的改进就是在现有的接口中增加了一些默认的方法实现，使用default关键字来修饰。这种做法不会影响以前代码对接口的实现，也对原有的接口进行了扩展。 传递行为给方法，而不是传递值。 /** * BiFunction是一个函数式接口，它接口两个参数并产生一个结果值返回。 * 它里面有一个apply(Object,Object)方法。 * @param &lt;T&gt; 函数的第一个参数类型 * @param &lt;U&gt; 函数的第二个参数类型 * @param &lt;R&gt; 函数的结果类型 * @since 1.8 */ @FunctionalInterface public interface BiFunction&lt;T, U, R&gt; { /** * 将apply函数应用到给定的参数上面 * * @param t 函数的第一个参数 * @param u 函数的第二个参数 * @return R 函数的结果 */ R apply(T t, U u); /** * 返回一个组合的函数，第一次是将该函数应用到它的输入，接着是将该函数的after应用到 * 之前的结果上。如果在任一函数评测期间抛出异常，它都会被传递给组合函数的调用者。 * @param &lt;V&gt; 组合函数和after函数的输出类型 * @param after 该函数应用将被在当前函数apply后被apply * @return 返回一个组合函数，第一次应用该函数，接着应用after函数 * @throws 当after为null的时候，会抛出NullPointerException异常。 */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); } } import java.util.function.BiFunction; import java.util.function.Function; public class BiFunctionTest { public static void main(String[] args){ BiFunctionTest test = new BiFunctionTest(); //实现四则运算 System.out.println(test.compute(4,2,(value1,value2)-&gt;value1+value2)); System.out.println(test.compute(4,2,(v1,v2)-&gt;v1-v2)); System.out.println(test.compute(1,2,(v1,v2)-&gt;v1*v2)); System.out.println(test.compute(3,2,(v1,v2)-&gt;v1/v2)); System.out.println(test.calcute(3,4,(v1,v2)-&gt;v1+v2,v-&gt;v * v)); } public int compute(int num1, int num2, BiFunction&lt;Integer,Integer,Integer&gt; biFunction){ return biFunction.apply(num1,num2); } public int calcute(int num1, int num2, BiFunction&lt;Integer,Integer,Integer&gt; biFunction, Function&lt;Integer,Integer&gt; function){ //调用addThen首先对接收的两个参数进行bifunction的apply，然后在进行function的apply return biFunction.andThen(function).apply(num1,num2); } } 输出结果： 6 2 2 1 49 BiConsumer BiConsumer&lt;T,U&gt;接口是java8 Function函数里面的接口，它有两个方法， BiConsumer用法很简单。 //接收参数 void accept(T t, U u) //默认方法，基本没什么用 default BiConsumer&lt;T,U&gt; andThen(BiConsumer&lt;? super T,? super U&gt; after) BiConsumer用法示例(java8)示例如下，andThen(biConsumer)方法没有什么效果(可不用)，主要是学会使用accept(T t, U u)方法，如下。 import java.util.function.BiConsumer; public class TestDemo { public static void main(String[] args) { BiConsumer&lt;String, String&gt; biConsumer = (x, y) -&gt; { System.out.println(x+&quot;===&quot;+y); }; biConsumer.andThen(biConsumer).accept(&quot;tpyyes.com &quot;, &quot; java8&quot;); } } 输出x与y参数的值，如下。 tpyyes.com === java8 tpyyes.com === java8 https://www.tpyyes.com/a/java/283.html http://www.manongjc.com/article/50415.html ","link":"https://kychill1986.github.io/post/java-8-bifunction-he-biconsumer-shi-yong/"},{"title":"Elasticsearch 聚合分页排序","content":"分页 请求JSON： GET oms_sku_shortage_order_index/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;oos&quot;: true } } ] } }, &quot;aggs&quot;: { &quot;by_wog&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;wog.keyword&quot;, &quot;size&quot;: 100000000 }, &quot;aggs&quot;: { &quot;sum_num&quot;: { &quot;sum&quot;: { &quot;field&quot;: &quot;num&quot; } }, &quot;bucket_field&quot;: { &quot;bucket_sort&quot;: { &quot;sort&quot;: [ { &quot;sum_num&quot;: { &quot;order&quot;: &quot;desc&quot; } } ], &quot;from&quot;: 0, &quot;size&quot;: 10 } } } } } } Java代码： SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); BoolQueryBuilder boolBuilder = QueryBuilders.boolQuery(); boolBuilder.must(QueryBuilders.matchQuery(&quot;oos&quot;, true)); if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getWarehouseCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;w.keyword&quot;, w)); } if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getOwnerCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;o.keyword&quot;, o)); } if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getGoodsCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;g.keyword&quot;, g)); } sourceBuilder.query(boolBuilder); TermsAggregationBuilder aggregation = AggregationBuilders.terms(&quot;by_wog&quot;).field(&quot;wog.keyword&quot;).size(100000); aggregation.subAggregation(AggregationBuilders.sum(&quot;sum_num&quot;).field(&quot;num&quot;)); List&lt;FieldSortBuilder&gt; fieldSorts = new ArrayList&lt;&gt;(); fieldSorts.add(new FieldSortBuilder(&quot;sum_num&quot;)); aggregation.subAggregation(new BucketSortPipelineAggregationBuilder(&quot;bucket_field&quot;, fieldSorts).from((pageQueryShortageBO.getPageNum() - 1) * pageQueryShortageBO.getPageSize()).size(pageQueryShortageBO.getPageSize())); sourceBuilder.aggregation(aggregation); SearchRequest searchRequest = new SearchRequest(&quot;shortage_index&quot;); searchRequest.types(ESConstants.TYPE); searchRequest.source(sourceBuilder); SearchResponse response = null; try { response = client.search(searchRequest, RequestOptions.DEFAULT); } catch (IOException e) { log.error(&quot;queryShortageFromES error: {}&quot;, e.getMessage(), e); } if (response != null) { Aggregations aggregations = response.getAggregations(); Terms byCompanyAggregation = aggregations.get(&quot;by_wog&quot;); List&lt;? extends Terms.Bucket&gt; buckets = byCompanyAggregation.getBuckets(); for (Terms.Bucket bucket : buckets) { Sum sum = bucket.getAggregations().get(&quot;sum_num&quot;); String wog = bucket.getKeyAsString(); String[] wogArray = wog.split(ESConstants.WOG_SPLIT_FLAG); } } 说明：因为bucket_sort是对聚合之后的桶进行分页排序,所以terms里面的size设置要大于bucket_sort里面分页大小，不然会取不到数据 计算count 请求JSON： GET oms_sku_shortage_order_index/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match&quot;: { &quot;oos&quot;: true }} ] } }, &quot;aggs&quot;: { &quot;by_wog&quot;: { &quot;cardinality&quot;: { &quot;field&quot;: &quot;wog.keyword&quot; } } } } Java代码： SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); BoolQueryBuilder boolBuilder = QueryBuilders.boolQuery(); boolBuilder.must(QueryBuilders.matchQuery(&quot;oos&quot;, true)); if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getWarehouseCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;w.keyword&quot;, w)); } if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getOwnerCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;o.keyword&quot;, o)); } if (CollectionUtils.isNotEmpty(pageQueryShortageBO.getGoodsCodeList())) { boolBuilder.must(QueryBuilders.termsQuery(&quot;g.keyword&quot;, g)); } sourceBuilder.query(boolBuilder); CardinalityAggregationBuilder aggregation = AggregationBuilders.cardinality(&quot;by_wog&quot;).field(&quot;wog.keyword&quot;); sourceBuilder.aggregation(aggregation); SearchRequest searchRequest = new SearchRequest(&quot;shortage_index&quot;); searchRequest.types(ESConstants.TYPE); searchRequest.source(sourceBuilder); SearchResponse response = null; try { response = client.search(searchRequest, RequestOptions.DEFAULT); } catch (IOException e) { log.error(&quot;getShortageTotalPage error: {}&quot;, e.getMessage(), e); } if (response != null) { Aggregations aggregations = response.getAggregations(); Cardinality byCompanyAggregation = aggregations.get(&quot;by_wog&quot;); return Integer.parseInt(String.valueOf(byCompanyAggregation.getValue())); } ","link":"https://kychill1986.github.io/post/elasticsearch-ju-he-fen-ye-pai-xu/"},{"title":"虚拟机内的ElasticSearch 7.6.0，可以在宿主机用IP进行访问(CentOS)","content":"🖥 ElasticSearch 对外可访问配置 1.关闭防火墙，或者加例外 a. 查看firewall服务状态 systemctl status firewalld b. 查看firewall的状态 firewall-cmd --state d. 开启、重启、关闭、firewalld.service服务 # 开启 service firewalld start # 重启 service firewalld restart # 关闭 service firewalld stop e. 查看防火墙规则 firewall-cmd --list-all f. 查询、开放、关闭端口 # 查询端口是否开放 firewall-cmd --query-port=8080/tcp # 开放80端口 firewall-cmd --permanent --add-port=80/tcp # 移除端口 firewall-cmd --permanent --remove-port=8080/tcp #重启防火墙(修改配置后要重启防火墙) firewall-cmd --reload # 参数解释 1、firwall-cmd：是Linux提供的操作firewall的一个工具； 2、--permanent：表示设置为持久； 3、--add-port：标识添加的端口； 2. 修改elasticsearch.yml network.host: 192.168.33.134 #可以直接写部署ES的IP http.port: 9200 node.name: node-1 bootstrap.memory_lock: false bootstrap.system_call_filter: false cluster.initial_master_nodes: [&quot;node-1&quot;] #这个“node-1”其实就是上面的“node.name”配置项 3. 修改linux系统配置 修改sysctl.conf sudo vim /etc/sysctl.conf vm.max_map_count=262144 检查配置是否生效 sysctl -a | grep “vm.max_map_count” 显示vm.max_map_count = 262144 编辑/etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 * soft nproc 4096 * hard nproc 4096 #以上的配置是针对root用户的 chill soft nofile 65536 chill hard nofile 65536 #以上的配置是针对chill用户的 这样在宿主机输入http://192.168.89.128:9200/，就可以看到es正常启动了 启动时查看elasticsearch.log日志，如果会看到如下的错误提示，那么按照上面的elasticsearch.yml，就可以解决，如果解决不了，可以针对问题直接baidu [3] bootstrap checks failed [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535] [2]: max number of threads [3790] for user [chill] is too low, increase to at least [4096] [3]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, clus ter.initial_master_nodes] must be configured ","link":"https://kychill1986.github.io/post/xu-ni-ji-nei-de-elasticsearch-760ke-yi-zai-su-zhu-ji-yong-ip-jin-xing-fang-wen-centos/"},{"title":"Mac 系统安装ElasticSearch","content":"🖥 包含单机安装，以及集群配置介绍... 单机安装 下载elasticSearch http://elastic.co 解压elasticSearch...tar.gz 启动elasticSearch ./bin/elasticsearch -d #后台运行 安装elasticSearch-head插件 下载elasticSearch-head，访问gitHub，搜索elasticSearch-head，在搜索结果里点击“mobz/elasticsearch-head” 解压elasticSearch-head cd '/Users/xxx/Documents/Tools/ElasticSearch/elasticsearch-head-master/' 安装最新版node brew install node 安装grunt npm install -g grunt-cli 在elasticsearch-head-master目录执行 npm install 如果安装过程中出现： 1. Failed at the phantomjs-prebuilt@2.1.15 install script ‘node install.js’. 解决方法： npm install phantomjs-prebuilt@2.1.15 --ignore-scripts 2. Local Npm module &quot;grunt-contrib-jasmine&quot; not found. Is it installed 解决办法： npm install grunt-contrib-jasmine --registry=https://registry.npm.taobao.org #使用国内镜像 启动elasticSearch-head npm run start 测试：http://serverip:9100/ 配置elasticsearch 使elasticSearch-head能正常访问（这两个是独立的进程，有跨域问题），修改elasticsearch，config/elasticsearch.yml文件，加入如下代码： http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 重新启动elasticsearch，访问elasticSearch-head，http://serverip:9100/ ElasticSearch集群配置 修改config/elasticsearch.yml文件 master: http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; cluster.name: chillcluster node.name: chillmaster node.master: true slave1: cluster.name: chillcluster node.name: slave1 network.host: 127.0.0.1 http.port: 9201 discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1&quot;] #找到master，如果不做这个配置那么这个节点就是游离于集群之外的 slave2: cluster.name: chillcluster node.name: slave2 network.host: 127.0.0.1 http.port: 9202 discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1&quot;] #找到master，如果不做这个配置那么这个节点就是游离于集群之外的 #彩蛋🎆 官方下载下来的elasticsearch安装包，直接解压，运行以前命令，也可以实现同样的集群效果 复杂的： ./elasticsearch -E node.name=chillmaster -E cluster.name=chillcluster -E node.master=true -E http.cors.enabled=true -E http.cors.allow-origin=&quot;*&quot; -E path.data=node1_data -d ./elasticsearch -E node.name=slave1 -E cluster.name=chillcluster -E network.host=127.0.0.1 -E http.port=9201 -E discovery.zen.ping.unicast.hosts=&quot;127.0.0.1&quot; -E path.data=node2_data -d ./elasticsearch -E node.name=slave2 -E cluster.name=chillcluster -E network.host=127.0.0.1 -E http.port=9202 -E discovery.zen.ping.unicast.hosts=&quot;127.0.0.1&quot; -E path.data=node3_data -d 简单的： ./elasticsearch -E node.name=node1 -E cluster.name=chillcluster -E path.data=node1_data -d ./elasticsearch -E node.name=node2 -E cluster.name=chillcluster -E path.data=node2_data -d ./elasticsearch -E node.name=node3 -E cluster.name=chillcluster -E path.data=node3_data -d 最后用http://127.0.0.1:9200/_cat/nodes，检查下是否正常 Reference https://blog.csdn.net/fenglailea/article/details/52934263 http://www.bubuko.com/infodetail-2108888.html ","link":"https://kychill1986.github.io/post/mac-xi-tong-an-zhuang-elasticsearch/"}]}